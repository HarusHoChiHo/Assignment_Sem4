{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a92c6d0-0cef-4632-82cf-7f3095fbd4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "raw",
   "id": "19e2ce6f-e2f8-4d64-a5a4-a7eb92c5e675",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "url = \"https://www.quanxue.cn/ct_nanhuaijin/zhongyong/zhongyong01.html\"\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d947eceb-e8f6-4b1f-928d-9dc8ec4d6f4a",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "paragraphs = [p.text for p in soup.find_all(\"p\")]\n",
    "paragraphs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09567209-3e53-4154-b0ea-eba4ef1eadea",
   "metadata": {},
   "source": [
    "gingman = [div.text for div in soup.find_all(\"div\", {\"class\": \"jingwen\"})]\n",
    "gingman"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b109eaa2-0c0f-4c54-a1e9-22f0422265f0",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "url = \"https://www.quanxue.cn/ct_nanhuaijin/zhongyongindex.html\"\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84955811-3d24-43fd-8ad6-6a53ab8a6611",
   "metadata": {},
   "source": [
    "links = [a[\"href\"] for a in soup.find_all(\"a\", href=True) if \"zhongyong\" in a[\"href\"]]\n",
    "prefix = \"https://www.quanxue.cn/ct_nanhuaijin/\"\n",
    "content_dict = {}\n",
    "for link in links:\n",
    "    response = requests.get(f\"{prefix}{link}\")\n",
    "    html_content = response.content\n",
    "    soup_temp = BeautifulSoup(html_content, 'html.parser')\n",
    "    # paragraphs = [p.text for p in soup_temp.find_all(\"p\")]\n",
    "    # gingman = [div.text for div in soup_temp.find_all(\"div\", {\"class\": \"jingwen\"})]\n",
    "    [content_dict[link]] = soup_temp.find_all(\"div\", {\"id\": \"page_global\"})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "476c9e8d-b6c8-406b-b9ef-e3e48e216d76",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "for key, value in content_dict.items():\n",
    "    [directory_name, file_name]=key.split(\"/\")\n",
    "    if not os.path.exists(directory_name):\n",
    "        os.makedirs(directory_name)\n",
    "    with open(f\"{directory_name}/{file_name}\", \"w\", encoding='utf-8') as file:\n",
    "        file.write(str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1c7b18-53ad-468a-b741-478bf936ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pprint\n",
    "index_url = \"https://www.quanxue.cn/index.html\"\n",
    "response = requests.get(index_url)\n",
    "html_content = response.content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "divs = soup.find_all(\"div\", id=re.compile(r'Dalei\\d+'))\n",
    "\n",
    "top_urls = []\n",
    "for div in divs:\n",
    "    top_urls.extend([link[\"href\"].replace(\"./\", \"\") for link in div.find_all(\"a\", {\"href\": re.compile(r\".*.html\")})])\n",
    "    \n",
    "pprint.pprint(top_urls)\n",
    "\n",
    "def get_content_url(url):\n",
    "    response = requests.get(url)\n",
    "    html_content = response.content\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    content_divs = soup.find_all(\"div\", id='index_left')\n",
    "    urls = []\n",
    "    for div in content_divs:\n",
    "        urls.extend([link[\"href\"].replace(\"./\", \"\") for link in div.find_all(\"a\", {\"href\": re.compile(r\".+\")})])\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edca232e-7528-49e1-9ab2-b9ed94242327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(url):\n",
    "    print(f\"---{url}\")\n",
    "    temp_response = requests.get(f\"https://www.quanxue.cn/{url}\")\n",
    "    temp_html_content = temp_response.content\n",
    "    temp_soup = BeautifulSoup(temp_html_content, 'html.parser')\n",
    "    parts = url.split(\"/\")\n",
    "    dict_name = \"\"\n",
    "    f_name = \"\"\n",
    "    pprint.pprint(parts)\n",
    "    if len(parts) > 2:\n",
    "        dict_name = parts[-2]\n",
    "        f_name = parts[-1]\n",
    "    else:\n",
    "        [dict_name, f_name] = parts\n",
    "    full_path = f\"{parts[0]}/{dict_name}\"\n",
    "    if not os.path.exists(full_path):\n",
    "        os.makedirs(full_path)\n",
    "    with open(f\"{full_path}/{f_name}\", \"a\", encoding='utf-8') as file:\n",
    "        file.write(str(temp_soup.find(\"body\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dd63e1-db42-4d2f-b3ed-67695a96b411",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total = len(top_urls)\n",
    "count = 1\n",
    "for url in top_urls:\n",
    "    print(f\"{count}/{total} - {url}\")\n",
    "    for content in get_content_url(f\"https://www.quanxue.cn/{url}\"):\n",
    "        modified_line = content\n",
    "        if \"http\" in modified_line:\n",
    "            continue\n",
    "        if modified_line.startswith(\"/\"):\n",
    "            modified_line = modified_line[1:]\n",
    "        if modified_line.startswith(\".\"):\n",
    "            modified_line = modified_line[1:]\n",
    "        if modified_line.find(\".html#\") >= 0:\n",
    "            modified_line = f\"{modified_line[:modified_line.find(\".html#\")+5]}\\n\"\n",
    "        with open(f\"urls.txt\", \"a\", encoding='utf-8') as file:\n",
    "            file.write(f\"{url.split(\"/\")[0]}/{str(modified_line)}\\n\")\n",
    "    count += 1\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd391618-bd0b-4040-a20b-cddc2c4e1331",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_set = set()\n",
    "with open(\"urls.txt\", \"r\") as file:\n",
    "    content = file.readlines()\n",
    "    for line in content:\n",
    "        if len(line.replace(\"\\n\",\"\")) > 0:\n",
    "            urls_set.add(line)\n",
    "urls_list = list(urls_set)\n",
    "urls_list.sort()\n",
    "with open(f\"filterd_urls.txt\", \"a\", encoding='utf-8') as filtered_file:\n",
    "    for line in urls_list:\n",
    "        filtered_file.write(line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a0d718-71ff-485f-9071-1681fb436466",
   "metadata": {},
   "outputs": [],
   "source": [
    "for content in urls_list:\n",
    "    modified_content = content.replace(\"\\n\",\"\")\n",
    "    print(modified_content)\n",
    "    get_content(modified_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9705229e-f961-4aa5-848e-c78ccf1d8959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
